{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50736e78-297b-455e-82df-7f64db24b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# NLP libraries\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a2f575-0ded-4cd7-8a59-b0ffa5bfae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score\n",
      "0   \"I love this product!\", Positive, Twitter, 202...                     \n",
      "1   \"The service was terrible.\", Negative, Yelp Re...                     \n",
      "2   \"This movie is amazing!\", Positive, IMDb, 2023...                     \n",
      "3   \"I'm so disappointed with their customer suppo...                     \n",
      "4   \"Just had the best meal of my life!\", Positive...                     \n",
      "..                                                ...                     \n",
      "93  \"I can't stop listening to this song. It's my ...                     \n",
      "94  \"Their website is so confusing and poorly desi...                     \n",
      "95  \"I had an incredible experience at the theme p...                     \n",
      "96                                                NaN                     \n",
      "97                                                NaN                     \n",
      "\n",
      "[98 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sentiment-analysis.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829fdf83-5ce5-4e3a-8d3b-a48fe023581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataframe_format(df):\n",
    "    \"\"\"Fix the dataframe where all columns are merged into one\"\"\"\n",
    "    if len(df.columns) == 1:\n",
    "        col_name = df.columns[0]\n",
    "        split_data = []\n",
    "        for index, row in df.iterrows():\n",
    "            if pd.notna(row[col_name]):\n",
    "                parts = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', str(row[col_name]))\n",
    "                split_data.append(parts)\n",
    "            else:\n",
    "                split_data.append([None] * 8)  # Now 8 columns including Rating\n",
    "        \n",
    "        fixed_df = pd.DataFrame(split_data, columns=[\n",
    "            'Text', 'Sentiment', 'Source', 'Date/Time', 'User ID', 'Location', 'Rating', 'Confidence Score'\n",
    "        ])\n",
    "    else:\n",
    "        fixed_df = df.copy()\n",
    "    \n",
    "    if 'Text' in fixed_df.columns:\n",
    "        fixed_df['Text'] = fixed_df['Text'].apply(\n",
    "            lambda x: re.sub(r'^\"|\"$', '', str(x)) if pd.notna(x) else x\n",
    "        )\n",
    "    \n",
    "    if 'Confidence Score' in fixed_df.columns:\n",
    "        fixed_df['Confidence Score'] = pd.to_numeric(\n",
    "            fixed_df['Confidence Score'], errors='coerce'\n",
    "        )\n",
    "    \n",
    "    if 'Rating' in fixed_df.columns:\n",
    "        fixed_df['Rating'] = pd.to_numeric(fixed_df['Rating'], errors='coerce')\n",
    "    \n",
    "    if 'Date/Time' in fixed_df.columns:\n",
    "        fixed_df['Date/Time'] = pd.to_datetime(\n",
    "            fixed_df['Date/Time'], errors='coerce'\n",
    "        )\n",
    "    \n",
    "    return fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2346a4-4530-4feb-bac0-0143f0d402ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the dataframe\n",
    "fixed_df = fix_dataframe_format(df)\n",
    "df=fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47fb043-7683-4c62-aece-65b1a945ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: (98, 8)\n",
      "After cleaning: (96, 8)\n",
      "Removed 2 rows with missing/invalid data\n"
     ]
    }
   ],
   "source": [
    "# Create a clean copy of the dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"Before cleaning:\", df_clean.shape)\n",
    "\n",
    "# Handle missing values\n",
    "df_clean = df_clean.dropna(subset=['Text', 'Sentiment', 'Date/Time'])\n",
    "\n",
    "# Convert Date/Time to datetime\n",
    "df_clean['Date/Time'] = pd.to_datetime(df_clean['Date/Time'], errors='coerce')\n",
    "\n",
    "# Remove invalid dates\n",
    "df_clean = df_clean.dropna(subset=['Date/Time'])\n",
    "\n",
    "# Ensure Confidence Score is numeric\n",
    "if 'Confidence Score' in df_clean.columns:\n",
    "    df_clean['Confidence Score'] = pd.to_numeric(df_clean['Confidence Score'], errors='coerce')\n",
    "    df_clean['Confidence Score'] = df_clean['Confidence Score'].fillna(0.5)\n",
    "\n",
    "print(\"After cleaning:\", df_clean.shape)\n",
    "print(f\"Removed {len(df) - len(df_clean)} rows with missing/invalid data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e1526b-dbe1-409f-89d0-70de5e3e95ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>extracted_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product!</td>\n",
       "      <td>i love this product</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service was terrible.</td>\n",
       "      <td>the service was terrible</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is amazing!</td>\n",
       "      <td>this movie is amazing</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm so disappointed with their customer support.</td>\n",
       "      <td>im so disappointed with their customer support</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just had the best meal of my life!</td>\n",
       "      <td>just had the best meal of my life</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Text  \\\n",
       "0                              I love this product!   \n",
       "1                         The service was terrible.   \n",
       "2                            This movie is amazing!   \n",
       "3  I'm so disappointed with their customer support.   \n",
       "4                Just had the best meal of my life!   \n",
       "\n",
       "                                     cleaned_text extracted_stars  \n",
       "0                             i love this product            None  \n",
       "1                        the service was terrible            None  \n",
       "2                           this movie is amazing            None  \n",
       "3  im so disappointed with their customer support            None  \n",
       "4               just had the best meal of my life            None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing\n",
    "df_clean['cleaned_text'] = df_clean['Text'].apply(preprocess_text)\n",
    "\n",
    "# Extract star ratings from text\n",
    "def extract_star_rating(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "        \n",
    "    text = str(text).lower()\n",
    "    patterns = [\n",
    "        r'(\\d+)\\s*stars?',\n",
    "        r'rating\\s*[:\\-]?\\s*(\\d+)',\n",
    "        r'(\\d+)/\\d+\\s*(?:stars?|rating)',\n",
    "        r'\\b(\\d+)\\s*out of\\s*\\d+\\s*stars?'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            return int(matches[0])\n",
    "    return None\n",
    "\n",
    "df_clean['extracted_stars'] = df_clean['Text'].apply(extract_star_rating)\n",
    "\n",
    "print(\"Text preprocessing completed!\")\n",
    "display(df_clean[['Text', 'cleaned_text', 'extracted_stars']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5773ee0f-ef5c-4a6a-b315-5f6f96c42f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>extracted_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.625</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_length  word_count  textblob_polarity extracted_stars\n",
       "0           19           4              0.625            None\n",
       "1           24           4             -1.000            None\n",
       "2           21           4              0.750            None\n",
       "3           46           7             -0.750            None\n",
       "4           33           8              1.000            None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create additional features\n",
    "df_clean['text_length'] = df_clean['cleaned_text'].apply(len)\n",
    "df_clean['word_count'] = df_clean['cleaned_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# TextBlob sentiment features\n",
    "df_clean['textblob_polarity'] = df_clean['Text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "df_clean['textblob_subjectivity'] = df_clean['Text'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "\n",
    "# Time-based features\n",
    "df_clean['date'] = pd.to_datetime(df_clean['Date/Time'])\n",
    "df_clean['day_of_week'] = df_clean['date'].dt.dayofweek\n",
    "df_clean['month'] = df_clean['date'].dt.month\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "display(df_clean[['text_length', 'word_count', 'textblob_polarity', 'extracted_stars']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e99bb51-c198-423c-9881-d5d81a5d5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Negative' 'Positive']\n",
      "Class distribution: [43 53]\n",
      "Final feature matrix shape: (96, 481)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X_text = df_clean['cleaned_text'].fillna('')\n",
    "y = df_clean['Sentiment']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "print(\"Class distribution:\", np.bincount(y_encoded))\n",
    "\n",
    "# Create TF-IDF features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# Combine with other features\n",
    "additional_features = df_clean[[\n",
    "    'text_length', 'word_count', 'textblob_polarity', \n",
    "    'textblob_subjectivity', 'day_of_week', 'month'\n",
    "]].fillna(0)\n",
    "\n",
    "# Handle star ratings\n",
    "star_ratings = df_clean['extracted_stars'].fillna(0)\n",
    "additional_features['star_rating'] = star_ratings\n",
    "\n",
    "# Combine all features\n",
    "from scipy.sparse import hstack\n",
    "X_combined = hstack([X_tfidf, additional_features.values])\n",
    "\n",
    "print(f\"Final feature matrix shape: {X_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9104e8-1e10-46cd-9f7f-5989fd0045d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Fixed preprocessing pipeline with proper NaN handling\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create column transformer with imputation\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(\n",
    "            max_features=3000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.8\n",
    "        ), 'cleaned_text'),\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),  # Handle missing numeric values\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['text_length', 'word_count', 'textblob_polarity', \n",
    "             'textblob_subjectivity', 'extracted_stars', \n",
    "             'day_of_week', 'month'])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c76226-843b-4ea4-8a0c-861f3bc5bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 76 samples\n",
      "Test set: 20 samples\n",
      " Logistic Regression Accuracy: 0.9500\n",
      " Logistic Regression CV Accuracy: 0.9600 (+/- 0.0653)\n",
      " Random Forest Accuracy: 0.9500\n",
      " Random Forest CV Accuracy: 0.9333 (+/- 0.0843)\n",
      " SVM Accuracy: 0.9500\n",
      " SVM CV Accuracy: 0.9350 (+/- 0.0792)\n",
      " Error training Naive Bayes: Negative values in data passed to MultinomialNB (input X).\n",
      "Skipping this classifier...\n",
      "\n",
      " BEST MODEL: Logistic Regression with accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Fixed - Define and train multiple classifiers with error handling\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import traceback\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42, probability=True),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "# Split the data - ensure we're using the cleaned dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_clean, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "results = {}\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Create pipeline with preprocessor and classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_proba = pipeline.predict_proba(X_test) if hasattr(classifier, 'predict_proba') else None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'pipeline': pipeline,\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        print(f\" {name} Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\" {name} CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_model = pipeline\n",
    "            best_model_name = name\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error training {name}: {str(e)}\")\n",
    "        print(\"Skipping this classifier...\")\n",
    "        continue\n",
    "\n",
    "if best_model:\n",
    "    print(f\"\\n BEST MODEL: {best_model_name} with accuracy: {best_score:.4f}\")\n",
    "else:\n",
    "    print(\"\\n No models were successfully trained. Checking data issues...\")\n",
    "    \n",
    "\n",
    "    numeric_features = ['text_length', 'word_count', 'textblob_polarity', \n",
    "                       'textblob_subjectivity', 'extracted_stars', 'day_of_week', 'month']\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        if feature in df_clean.columns:\n",
    "            nan_count = df_clean[feature].isna().sum()\n",
    "            print(f\"  {feature}: {nan_count} NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d288b94-dfcb-4906-9ffa-861f060b49f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentiment filter initialized with best model\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Fixed sentiment filtering class that works with both model types\n",
    "class CustomerSentimentFilter:\n",
    "    def __init__(self, model, label_encoder, vectorizer=None, model_type='pipeline'):\n",
    "        self.model = model\n",
    "        self.label_encoder = label_encoder\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model_type = model_type  # 'pipeline' or 'simple'\n",
    "        \n",
    "    def predict_single(self, text, date_time=None):\n",
    "        \"\"\"Predict sentiment for a single text\"\"\"\n",
    "        try:\n",
    "            if self.model_type == 'pipeline':\n",
    "                # For pipeline models\n",
    "                single_data = pd.DataFrame([{\n",
    "                    'cleaned_text': preprocess_text(text),\n",
    "                    'text_length': len(preprocess_text(text)),\n",
    "                    'word_count': len(preprocess_text(text).split()),\n",
    "                    'textblob_polarity': TextBlob(str(text)).sentiment.polarity,\n",
    "                    'textblob_subjectivity': TextBlob(str(text)).sentiment.subjectivity,\n",
    "                    'extracted_stars': extract_star_rating(text),\n",
    "                    'day_of_week': datetime.now().weekday() if date_time is None else pd.to_datetime(date_time).weekday(),\n",
    "                    'month': datetime.now().month if date_time is None else pd.to_datetime(date_time).month\n",
    "                }])\n",
    "                \n",
    "                prediction = self.model.predict(single_data)[0]\n",
    "                probability = self.model.predict_proba(single_data)[0]\n",
    "                \n",
    "            else:\n",
    "                # For simple models (text only)\n",
    "                cleaned_text = preprocess_text(text)\n",
    "                text_features = self.vectorizer.transform([cleaned_text])\n",
    "                prediction = self.model.predict(text_features)[0]\n",
    "                probability = self.model.predict_proba(text_features)[0]\n",
    "            \n",
    "            sentiment = self.label_encoder.inverse_transform([prediction])[0]\n",
    "            confidence = probability[prediction]\n",
    "            stars = extract_star_rating(text)\n",
    "            \n",
    "            return sentiment, confidence, stars\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            return \"Unknown\", 0.0, None\n",
    "    \n",
    "    def filter_positive_feedback(self, df, min_confidence=0.7, min_stars=3):\n",
    "        \"\"\"Filter positive feedback from last 1 year\"\"\"\n",
    "\n",
    "        \n",
    "        # Filter data from last 1 year\n",
    "        if 'Date/Time' in df.columns:\n",
    "            one_year_ago = datetime.now() - timedelta(days=365)\n",
    "            recent_data = df[df['Date/Time'] >= one_year_ago].copy()\n",
    "        else:\n",
    "            recent_data = df.copy()\n",
    "            print(\"  No Date/Time column - using all data\")\n",
    "        \n",
    "        print(f\" Reviews from last 1 year: {len(recent_data)}\")\n",
    "        \n",
    "        # Predict sentiments\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        stars_list = []\n",
    "        \n",
    "        for idx, row in recent_data.iterrows():\n",
    "            sentiment, confidence, stars = self.predict_single(\n",
    "                row['Text'], \n",
    "                row['Date/Time'] if 'Date/Time' in row else None\n",
    "            )\n",
    "            predictions.append(sentiment)\n",
    "            confidences.append(confidence)\n",
    "            stars_list.append(stars)\n",
    "        \n",
    "        recent_data['predicted_sentiment'] = predictions\n",
    "        recent_data['prediction_confidence'] = confidences\n",
    "        recent_data['extracted_stars'] = stars_list\n",
    "        \n",
    "        # Apply filters\n",
    "        positive_mask = (\n",
    "            (recent_data['predicted_sentiment'] == 'Positive') &\n",
    "            (recent_data['prediction_confidence'] >= min_confidence) &\n",
    "            (\n",
    "                (recent_data['extracted_stars'] >= min_stars) |\n",
    "                (recent_data['extracted_stars'].isna()) |\n",
    "                (recent_data['prediction_confidence'] > 0.8)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        positive_feedback = recent_data[positive_mask].copy()\n",
    "        \n",
    "        # Sort by date and confidence\n",
    "        if 'Date/Time' in positive_feedback.columns:\n",
    "            positive_feedback = positive_feedback.sort_values(\n",
    "                ['Date/Time', 'prediction_confidence'], \n",
    "                ascending=[False, False]\n",
    "            )\n",
    "        else:\n",
    "            positive_feedback = positive_feedback.sort_values('prediction_confidence', ascending=False)\n",
    "        \n",
    "        return positive_feedback\n",
    "\n",
    "# Initialize the filter\n",
    "if results:\n",
    "    best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "    best_result = results[best_model_name]\n",
    "    \n",
    "    if 'pipeline' in best_result:\n",
    "        # Pipeline model\n",
    "        sentiment_filter = CustomerSentimentFilter(\n",
    "            best_result['pipeline'], \n",
    "            label_encoder,\n",
    "            model_type='pipeline'\n",
    "        )\n",
    "    else:\n",
    "        # Simple model\n",
    "        sentiment_filter = CustomerSentimentFilter(\n",
    "            best_result['model'],\n",
    "            label_encoder,\n",
    "            vectorizer=best_result['vectorizer'],\n",
    "            model_type='simple'\n",
    "        )\n",
    "    print(\" Sentiment filter initialized with best model\")\n",
    "else:\n",
    "    print(\" Cannot initialize filter - no models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b6b6ef-ce77-47fd-90e9-495a7fcc9cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved as: feedback_review_model20251031_2355.pkl\n"
     ]
    }
   ],
   "source": [
    "# Quick save cell - run this if you just want to save without all the extras\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Quick save function\n",
    "def quick_save_model():\n",
    "    if results:\n",
    "        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "        best_result = results[best_model_name]\n",
    "        \n",
    "        model_assets = {\n",
    "            'model': best_result['pipeline'] if 'pipeline' in best_result else best_result['model'],\n",
    "            'label_encoder': label_encoder,\n",
    "            'best_model_name': best_model_name,\n",
    "            'accuracy': best_result['accuracy'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        if 'vectorizer' in best_result:\n",
    "            model_assets['vectorizer'] = best_result['vectorizer']\n",
    "        \n",
    "        filename = f\"feedback_review_model{datetime.now().strftime('%Y%m%d_%H%M')}.pkl\"\n",
    "        joblib.dump(model_assets, filename)\n",
    "        print(f\" Model saved as: {filename}\")\n",
    "        return filename\n",
    "    else:\n",
    "        print(\" No models to save\")\n",
    "        return None\n",
    "\n",
    "# Quick save\n",
    "saved_model_path = quick_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9bc68-7219-4feb-b16a-6584097a8eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509669d0-d448-4848-a092-0622c5d32c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
